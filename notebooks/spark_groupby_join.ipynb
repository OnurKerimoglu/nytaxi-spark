{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10769530-d6bf-490e-ace3-6ea8765c304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d1d4ed-3f18-4dcb-ac16-1479ba1ada09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapath: /home/onur/repos/nytaxi-spark/data\n"
     ]
    }
   ],
   "source": [
    "rootpath = os.path.dirname(os.path.abspath(\"\"))\n",
    "datapath = os.path.join(rootpath, 'data')\n",
    "print(f\"datapath: {datapath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396c466f-590a-49e9-91cd-8f50450dfbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/13 13:28:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[2]') \\\n",
    "    .appName('taxi_groupby') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ecaa5-5b01-481a-b2c5-0aefbd13e2ca",
   "metadata": {},
   "source": [
    "### Read and Combine Green&Yellow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2522b1e4-b22a-4858-b607-a5200762bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet(os.path.join(datapath, 'pq', 'green', '*', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "722894fe-c964-41f9-b6ba-71fcbaa35e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'lpep_pickup_datetime',\n",
       " 'lpep_dropoff_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bed5a0-20fb-4e6d-8d09-2c3d0e66e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onur/opt/spark355/spark-3.5.5-bin-hadoop3/python/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_green.registerTempTable('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbfca1-a084-44be-8379-f5be098fb694",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e201821-4b3f-4c9c-95e3-4cf1f2a6ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+------------------+--------------+\n",
      "|               hour|rzone|            amount|number_records|\n",
      "+-------------------+-----+------------------+--------------+\n",
      "|2020-01-01 00:00:00|    7| 769.7299999999996|            45|\n",
      "|2020-01-01 00:00:00|   17|195.03000000000003|             9|\n",
      "|2020-01-01 00:00:00|   18|               7.8|             1|\n",
      "|2020-01-01 00:00:00|   22|              15.8|             1|\n",
      "|2020-01-01 00:00:00|   24|              87.6|             3|\n",
      "|2020-01-01 00:00:00|   25| 531.0000000000002|            26|\n",
      "|2020-01-01 00:00:00|   29|              61.3|             1|\n",
      "|2020-01-01 00:00:00|   32| 68.94999999999999|             2|\n",
      "|2020-01-01 00:00:00|   33|317.27000000000004|            11|\n",
      "|2020-01-01 00:00:00|   35|            129.96|             5|\n",
      "|2020-01-01 00:00:00|   36|295.34000000000003|            11|\n",
      "|2020-01-01 00:00:00|   37|            175.67|             6|\n",
      "|2020-01-01 00:00:00|   38| 98.78999999999999|             2|\n",
      "|2020-01-01 00:00:00|   40|168.97999999999996|             8|\n",
      "|2020-01-01 00:00:00|   41|1363.9599999999987|            84|\n",
      "|2020-01-01 00:00:00|   42| 799.7599999999994|            52|\n",
      "|2020-01-01 00:00:00|   43|            107.52|             6|\n",
      "|2020-01-01 00:00:00|   47|              13.3|             1|\n",
      "|2020-01-01 00:00:00|   49|266.76000000000005|            14|\n",
      "|2020-01-01 00:00:00|   51|              17.8|             2|\n",
      "+-------------------+-----+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select \n",
    "-- Revenue grouping \n",
    "date_trunc(\"hour\", lpep_pickup_datetime) as hour,\n",
    "PULocationID as rzone,\n",
    "-- Revenue calculation \n",
    "sum(total_amount) as amount,\n",
    "COUNT(1) as number_records\n",
    "from green\n",
    "WHERE\n",
    "lpep_pickup_datetime >= '2020-01-01'\n",
    "group by \n",
    "1,2\n",
    "order by\n",
    "1,2\n",
    "\"\"\"\n",
    "df_green_hr = spark.sql(query)\n",
    "df_green_hr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "233dfb7b-783c-48d4-be5a-4fd1b779a4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green.write.parquet(os.path.join(datapath, 'report', 'revenue_hourly_green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c8a8145-f965-4c27-a302-c8e010217929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yellow = spark.read.parquet(os.path.join(datapath, 'pq', 'yellow', '*', '*'))\n",
    "df_yellow.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3cc3282-c927-4048-840e-5551e79ef0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.registerTempTable('yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90a586cf-8c15-421f-a1dc-f782a8b1dc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+------------------+--------------+\n",
      "|               hour|rzone|            amount|number_records|\n",
      "+-------------------+-----+------------------+--------------+\n",
      "|2020-01-01 00:00:00|    3|              25.0|             1|\n",
      "|2020-01-01 00:00:00|    4|1004.3000000000002|            57|\n",
      "|2020-01-01 00:00:00|    7| 455.1700000000001|            38|\n",
      "|2020-01-01 00:00:00|   10|             42.41|             2|\n",
      "|2020-01-01 00:00:00|   12|             107.0|             6|\n",
      "|2020-01-01 00:00:00|   13|1214.8000000000002|            56|\n",
      "|2020-01-01 00:00:00|   14|               8.8|             1|\n",
      "|2020-01-01 00:00:00|   15|             34.09|             1|\n",
      "|2020-01-01 00:00:00|   17|220.20999999999998|             8|\n",
      "|2020-01-01 00:00:00|   18|               5.8|             1|\n",
      "|2020-01-01 00:00:00|   24| 754.9500000000002|            45|\n",
      "|2020-01-01 00:00:00|   25|            324.35|            16|\n",
      "|2020-01-01 00:00:00|   32|              18.0|             1|\n",
      "|2020-01-01 00:00:00|   33|            255.56|             8|\n",
      "|2020-01-01 00:00:00|   34|              19.3|             1|\n",
      "|2020-01-01 00:00:00|   36|            109.17|             3|\n",
      "|2020-01-01 00:00:00|   37|161.60999999999999|             7|\n",
      "|2020-01-01 00:00:00|   40|             89.97|             5|\n",
      "|2020-01-01 00:00:00|   41|1256.5299999999997|            80|\n",
      "|2020-01-01 00:00:00|   42| 635.3500000000001|            46|\n",
      "+-------------------+-----+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select \n",
    "-- Revenue grouping \n",
    "date_trunc(\"hour\", tpep_pickup_datetime) as hour,\n",
    "PULocationID as rzone,\n",
    "-- Revenue calculation \n",
    "sum(total_amount) as amount,\n",
    "COUNT(1) as number_records\n",
    "from yellow\n",
    "WHERE\n",
    "tpep_pickup_datetime >= '2020-01-01'\n",
    "group by \n",
    "1,2\n",
    "order by\n",
    "1,2\n",
    "\"\"\"\n",
    "df_yellow_hr = spark.sql(query)\n",
    "df_yellow_hr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1c02e1f-b32b-48e9-9625-e51eff9c6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow.write.parquet(os.path.join(datapath, 'report', 'revenue_hourly_yellow'), mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fc3f58-9017-4c43-86d3-4ac918a26b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2072ff-3979-45d7-9d14-7e3301a1315b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ab42727-9ad8-4beb-a0ff-bf2744573505",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
